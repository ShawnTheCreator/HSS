# Project: Anomalous Login Detection System

## Overview

This project implements a machine learning-based system to detect anomalous user logins. It uses a Flask web application ([app.py](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Capp.py)) to capture login attempt details, process them, and predict if a login is "Normal" or an "Anomaly" using a pre-trained Isolation Forest model. Detected events are logged for auditing and potential model retraining.

## How it Works

1.  **Data Collection**: When a user accesses the root (`/`) endpoint of the Flask application, it captures their IP address, User-Agent string, and (if available from the session) `user_id` and `role`.
2.  **Feature Enrichment**:
    *   The IP address is used to fetch geographical information (city, country, ISP) via an external API (`http://ip-api.com`).
    *   Date and time features (hour, weekday) are extracted.
    *   User-Agent string is parsed to attempt to identify OS and browser.
3.  **Feature Encoding**: Categorical features (location, ISP, role, OS, browser, device type, user ID) are converted to numerical representations using pre-fitted `LabelEncoder`s.
4.  **Prediction**: The numerical feature vector is fed into a pre-trained Isolation Forest model ([models/isolation_forest.pkl](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Cmodels%5Cisolation_forest.pkl)) to classify the login attempt.
5.  **Logging & Notification**:
    *   The raw login details, processed features, and classification result are logged to [outputs/logs.txt](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Coutputs%5Clogs.txt).
    *   Details are printed to the console.
    *   A placeholder function ([`send_to_email`](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Capp.py)) exists for email notifications.
6.  **Redirection**: After processing, the user is redirected to Google.
7.  **API Endpoint**: A `/predict` endpoint is available for direct JSON-based predictions.
8.  **Test Login**: A `/login-test` route in [app.py](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Capp.py) can be used to simulate a user login by setting session variables.

## Key Components

*   **[app.py](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Capp.py)**: The main Flask application handling requests, feature processing, prediction, and logging.
*   **[notebooks/01_train_model.ipynb](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Cnotebooks%5C01_train_model.ipynb)**: Jupyter notebook used to train the LabelEncoders and the Isolation Forest model. This is the source for the `.pkl` files in the `models/` directory.
*   **`models/` directory**: Contains pickled Scikit-learn LabelEncoders for various features and the trained Isolation Forest model (`isolation_forest.pkl`).
*   **`data/` directory**:
    *   [data/expanded_login_metadata.csv](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Cdata%5Cexpanded_login_metadata.csv): Raw training data.
    *   [data/numeric_login_data.csv](c%3A%5CUsers%Vukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Cdata%5Cnumeric_login_data.csv): Numerically encoded data generated by the training notebook.
*   **[outputs/logs.txt](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Coutputs%5Clogs.txt)**: Stores JSON logs of processed login events.
*   **[src/model.py](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Csrc%5Cmodel.py)**: A utility script that can load data and train a model, or load a pre-trained model for predictions. Note that the primary training process is defined in the notebook.
*   **[index.html](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Cindex.html)**: A simple HTML page that links to a deployed version of the application.

## Setup

1.  **Clone the repository.**
2.  **Create a Python virtual environment and activate it.**
3.  **Install dependencies:**
    The [requirements.txt](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Crequirements.txt) file appears to have encoding issues (null characters). It should be a plain UTF-8 text file. Once corrected, run:
    ````sh
    pip install -r requirements.txt
    ````
4.  **Ensure Models are Present**: The `models/` directory should contain all necessary `.pkl` files. If not, you may need to run the [notebooks/01_train_model.ipynb](c%3A%5CUsers%5CVukile%5COneDrive%5CDocuments%5CTextBooks%5CSS25HACK%5Csec%20summit%20-%20Copy%5Cnotebooks%5C01_train_model.ipynb) notebook to generate them.

## Running the Application

Execute the Flask app:
````sh
python app.py


Areas of Caution / Important Notes
Model-Encoder Consistency: The LabelEncoders (.pkl files in models) loaded by app.py must be the exact ones generated by the notebooks/01_train_model.ipynb notebook using the same data and logic. If the notebook is re-run or the training data changes, these files must be updated.
Feature Engineering in make_feature_dict: The logic within the make_feature_dict function (e.g., OS/browser parsing, default values for device_type, session_duration) is critical. Any changes here must align with how the model was trained or may necessitate retraining.
"UNKNOWN" Value Handling: The system is designed to handle unseen categorical values by mapping them to an "UNKNOWN" category, which the encoders are trained to recognize (see safe_transform).
External API Dependency: Location information relies on http://ip-api.com. Service availability, rate limits, or API changes can affect feature generation. The error handling for this API call in get_location_info is basic.
Session Data: The main / route expects user_id and role to be present in the Flask session. The /login-test route provides a way to set these for testing. Ensure a proper authentication mechanism sets these session variables in a production environment.
Email Notification: The send_to_email function is a placeholder and needs to be implemented with actual email server details and credentials for alerts to be sent.
Hardcoded Feature Values: Some features in make_feature_dict (e.g., device_type: "Desktop", login_success: 1, session_duration: 30) are hardcoded for prediction. Verify if these should be dynamic based on actual login attempt data. The training data shows variability in these fields.
requirements.txt Encoding: The provided requirements.txt file has unusual null characters. This should be corrected to a standard plain text UTF-8 encoded file for pip install -r requirements.txt to work reliably.
Model Retraining Strategy: While logs are collected in outputs/logs.txt for potential retraining, a formal process for using this data to update the model and encoders needs to be established.
Flask Secret Key: The app.secret_key in app.py is set to a default placeholder ("your-flask-secret"). For any deployment, this must be changed to a strong, unique, and securely managed secret.